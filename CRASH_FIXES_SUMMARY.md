# CorreÃ§Ãµes de Problemas CrÃ­ticos - Resumo TÃ©cnico

Este documento descreve as 8 correÃ§Ãµes crÃ­ticas implementadas para prevenir crashes do sistema.

## ğŸ”´ Problema 1: Vazamento de MemÃ³ria GPU

### DescriÃ§Ã£o do Problema
ApÃ³s cada transcriÃ§Ã£o, o modelo Whisper nÃ£o estava liberando a memÃ³ria GPU adequadamente, causando **Out of Memory (OOM)** apÃ³s aproximadamente 10 requisiÃ§Ãµes.

### SoluÃ§Ã£o Implementada
**Arquivo:** `transcription/services.py`

```python
# Criar resultado antes de limpar memÃ³ria
result = TranscriptionResult(...)

# âœ… CRITICAL FIX: Limpar memÃ³ria GPU apÃ³s cada transcriÃ§Ã£o
if "cuda" in device:
    memory_after = cls.check_gpu_memory()
    logger.debug(f"MemÃ³ria GPU apÃ³s transcriÃ§Ã£o: {memory_after}")
    cls.clear_gpu_memory()
    memory_final = cls.check_gpu_memory()
    logger.info(f"MemÃ³ria GPU apÃ³s limpeza: {memory_final.get('free_gb', 0):.2f}GB livres")

return result
```

### BenefÃ­cios
- âœ… Libera memÃ³ria GPU apÃ³s cada transcriÃ§Ã£o via `torch.cuda.empty_cache()`
- âœ… Logging detalhado do uso de memÃ³ria (antes/depois)
- âœ… Previne OOM em workloads de alta carga
- âœ… Sistema pode processar requisiÃ§Ãµes indefinidamente

---

## ğŸ”´ Problema 2: ValidaÃ§Ã£o de Tamanho de Arquivo

### DescriÃ§Ã£o do Problema
O tamanho do arquivo era validado **DEPOIS** de carregar todo o conteÃºdo na memÃ³ria usando `len(file.read())`, causando **OOM** para arquivos grandes (> 500MB).

### SoluÃ§Ã£o Implementada
**Arquivo:** `transcription/api.py`

```python
# âœ… CRITICAL FIX: Validar tamanho ANTES de carregar na memÃ³ria
if hasattr(file, 'size'):
    file_size_mb = file.size / (1024 * 1024)
else:
    # Fallback para arquivos que nÃ£o tÃªm metadata
    file_size_mb = len(file.read()) / (1024 * 1024)
    file.seek(0)

if file_size_mb > settings.MAX_AUDIO_SIZE_MB:
    return TranscriptionResponse(
        success=False,
        error=f"Arquivo muito grande: {file_size_mb:.2f}MB"
    )
```

### BenefÃ­cios
- âœ… Usa metadata do arquivo (`file.size`) em vez de ler conteÃºdo
- âœ… Previne OOM antes de carregar arquivo grande
- âœ… Resposta rÃ¡pida para arquivos invÃ¡lidos
- âœ… Fallback seguro para sistemas sem metadata

---

## ğŸ”´ Problema 3: Deadlock em Processamento AssÃ­ncrono

### DescriÃ§Ã£o do Problema
Tasks Celery podiam ficar penduradas indefinidamente sem timeout ou retry adequado, causando workers mortos e fila travada.

### SoluÃ§Ã£o Implementada
**Arquivo:** `transcription/tasks.py`

```python
@shared_task(
    bind=True,
    name='transcription.transcribe_audio_async',
    time_limit=1800,  # 30 minutos (hard limit)
    soft_time_limit=1700,  # 28 minutos (warning)
    max_retries=2,
    default_retry_delay=60,
    # âœ… CRITICAL FIX: ConfiguraÃ§Ãµes para evitar deadlock
    acks_late=True,  # Reconhece apenas apÃ³s conclusÃ£o
    reject_on_worker_lost=True,  # Rejeita se worker morrer
    autoretry_for=(Exception,),  # Retry automÃ¡tico
    retry_backoff=True,  # Backoff exponencial
    retry_backoff_max=600,  # Max 10 minutos entre retries
    retry_jitter=True  # Jitter aleatÃ³rio
)
```

### BenefÃ­cios
- âœ… `acks_late=True`: Task sÃ³ confirmada apÃ³s sucesso
- âœ… `reject_on_worker_lost=True`: Reprocessa se worker morrer
- âœ… Retry automÃ¡tico com backoff exponencial
- âœ… Jitter aleatÃ³rio previne "thundering herd"
- âœ… Timeouts claros (hard/soft)

---

## ğŸŸ  Problema 4: AcÃºmulo de Arquivos TemporÃ¡rios

### DescriÃ§Ã£o do Problema
Arquivos `.wav` temporÃ¡rios nÃ£o eram deletados em caso de erro, causando **disco cheio** em 24 horas.

### SoluÃ§Ã£o Implementada
**Arquivo:** `transcription/services.py`

```python
# âœ… CRITICAL FIX: Context manager para limpeza garantida
@contextmanager
def temporary_file(file_path: Optional[str] = None):
    """Garante limpeza de arquivos temporÃ¡rios"""
    try:
        yield file_path
    finally:
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
                logger.debug(f"Arquivo temporÃ¡rio removido: {file_path}")
            except Exception as e:
                logger.warning(f"Erro ao remover arquivo: {e}")
```

```python
finally:
    # âœ… Garantir limpeza mesmo em caso de erro
    if temp_wav_path and os.path.exists(temp_wav_path):
        try:
            os.remove(temp_wav_path)
            logger.info(f"Arquivo temporÃ¡rio removido: {temp_wav_path}")
        except Exception as e:
            logger.error(f"CRÃTICO: Falha ao remover arquivo: {e}")
            # Tentar forÃ§ar remoÃ§Ã£o alterando permissÃµes
            try:
                os.chmod(temp_wav_path, 0o777)
                os.remove(temp_wav_path)
                logger.info(f"Removido apÃ³s alterar permissÃµes")
            except Exception as e2:
                logger.error(f"CRÃTICO: ImpossÃ­vel remover: {e2}")
```

### BenefÃ­cios
- âœ… Context manager para limpeza automÃ¡tica
- âœ… Bloco `finally` garante execuÃ§Ã£o
- âœ… Fallback com alteraÃ§Ã£o de permissÃµes
- âœ… Logging detalhado de falhas
- âœ… Previne disco cheio

---

## ğŸŸ  Problema 5: Redis/Celery DesconexÃ£o NÃ£o Tratada

### DescriÃ§Ã£o do Problema
Sem retry automÃ¡tico em desconexÃ£o Redis, a fila de tasks quebrava completamente.

### SoluÃ§Ã£o Implementada
**Arquivo:** `config/celery.py`

```python
# âœ… CRITICAL FIX: ConfiguraÃ§Ãµes para robustez contra desconexÃ£o Redis
app.conf.update(
    # Retry automÃ¡tico em caso de falha de conexÃ£o
    broker_connection_retry_on_startup=True,
    broker_connection_retry=True,
    broker_connection_max_retries=10,
    broker_connection_timeout=10,
    
    # ConfiguraÃ§Ãµes de resiliÃªncia
    result_backend_transport_options={
        'socket_keepalive': True,
        'socket_keepalive_options': {
            1: 1,  # TCP_KEEPIDLE
            2: 1,  # TCP_KEEPINTVL
            3: 5,  # TCP_KEEPCNT
        },
        'retry_on_timeout': True,
        'health_check_interval': 30,
    },
    
    broker_transport_options={
        'socket_keepalive': True,
        'retry_on_timeout': True,
        'health_check_interval': 30,
    },
)
```

### BenefÃ­cios
- âœ… Retry automÃ¡tico na conexÃ£o (max 10 tentativas)
- âœ… Socket keepalive para detectar desconexÃµes
- âœ… Health check a cada 30 segundos
- âœ… Retry em timeout de operaÃ§Ãµes
- âœ… Sistema se recupera automaticamente

---

## ğŸŸ  Problema 6: Cache Corrompido Causa Loop Infinito

### DescriÃ§Ã£o do Problema
Dados corrompidos no cache eram retornados sem validaÃ§Ã£o, causando crashes em loop infinito.

### SoluÃ§Ã£o Implementada
**Arquivo:** `transcription/cache_manager.py`

```python
def get(self, cache_key: str) -> Optional[Dict[str, Any]]:
    """Busca com validaÃ§Ã£o de integridade"""
    cached_data = self.memory_cache.get(cache_key)
    if cached_data:
        # âœ… CRITICAL FIX: Validar dados antes de retornar
        if self._validate_cached_data(cached_data):
            return cached_data
        else:
            logger.warning(f"Dados corrompidos no cache: {cache_key[:16]}...")
            self.memory_cache._remove(cache_key)
            return None
    return None

def _validate_cached_data(self, data: Dict[str, Any]) -> bool:
    """Valida integridade dos dados do cache"""
    # Verificar estrutura bÃ¡sica
    if not isinstance(data, dict):
        return False
    
    # Verificar campos obrigatÃ³rios
    required_fields = ['success', 'transcription', 'audio_info']
    for field in required_fields:
        if field not in data:
            return False
    
    # Validar tipos
    if not isinstance(data['success'], bool):
        return False
    
    # Se success=True, validar transcriÃ§Ã£o
    if data['success']:
        transcription = data.get('transcription')
        if not transcription or not isinstance(transcription, dict):
            return False
        
        # Validar campos da transcriÃ§Ã£o
        trans_required = ['text', 'segments', 'language', 'duration']
        for field in trans_required:
            if field not in transcription:
                return False
    
    return True
```

### BenefÃ­cios
- âœ… ValidaÃ§Ã£o completa de estrutura e tipos
- âœ… Remove automaticamente dados corrompidos
- âœ… Previne crashes por dados invÃ¡lidos
- âœ… ValidaÃ§Ã£o em memÃ³ria e disco
- âœ… Logging detalhado de problemas

---

## ğŸŸ  Problema 7: VÃ­deo Corrompido Causa Hang Indefinido

### DescriÃ§Ã£o do Problema
FFmpeg podia pendurar indefinidamente em vÃ­deos corrompidos, matando workers.

### SoluÃ§Ã£o Implementada
**Arquivo:** `transcription/video_processor.py`

```python
@staticmethod
def validate_video_file(file_path: str, timeout: int = 10) -> Tuple[bool, Optional[str]]:
    """Valida com timeout para evitar hang"""
    try:
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-select_streams', 'a:0',
             '-show_entries', 'stream=codec_type', '-of', 'csv=p=0',
             file_path],
            capture_output=True,
            text=True,
            timeout=timeout  # âœ… Timeout configurÃ¡vel
        )
        # ... validaÃ§Ã£o
    except subprocess.TimeoutExpired:
        logger.error(f"Timeout ao validar vÃ­deo ({timeout}s)")
        return False, f"Timeout ao validar arquivo ({timeout}s). Pode estar corrompido."
```

```python
@staticmethod
def extract_audio(video_path: str, output_path: str, timeout: int = 600) -> Tuple[bool, str]:
    """Extrai Ã¡udio com timeout adaptativo"""
    # âœ… CRITICAL FIX: Timeout adaptativo baseado no tamanho
    file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
    adaptive_timeout = max(60, min(int(file_size_mb * 1.0), 1800))
    actual_timeout = max(timeout, adaptive_timeout)
    
    logger.info(f"VÃ­deo: {file_size_mb:.2f}MB, timeout: {actual_timeout}s")
    
    result = subprocess.run(
        command,
        capture_output=True,
        text=True,
        timeout=actual_timeout  # âœ… Timeout adaptativo
    )
```

### BenefÃ­cios
- âœ… Timeout adaptativo: 1s por MB de vÃ­deo
- âœ… MÃ­nimo 60s, mÃ¡ximo 1800s (30 min)
- âœ… Detecta vÃ­deos corrompidos rapidamente
- âœ… Logging do timeout calculado
- âœ… Mensagens de erro claras

---

## ğŸŸ¡ Problema 8: Docker Entrypoint Race Condition

### DescriÃ§Ã£o do Problema
MÃºltiplas replicas executando `migrate` simultaneamente causavam crashes no startup.

### SoluÃ§Ã£o Implementada
**Arquivo:** `docker-entrypoint.sh`

```bash
# âœ… CRITICAL FIX: File lock para evitar race condition
LOCK_FILE="/tmp/daredevil_migrate.lock"
LOCK_TIMEOUT=300  # 5 minutos

acquire_lock() {
  local timeout=$1
  local elapsed=0
  
  while [ $elapsed -lt $timeout ]; do
    # Tentar criar lock (operaÃ§Ã£o atÃ´mica)
    if mkdir "$LOCK_FILE" 2>/dev/null; then
      echo "Lock adquirido"
      return 0
    fi
    
    # Verificar se lock estÃ¡ obsoleto (>10 min)
    if [ -d "$LOCK_FILE" ]; then
      lock_age=$(($(date +%s) - $(stat -c %Y "$LOCK_FILE" 2>/dev/null || echo 0)))
      if [ $lock_age -gt 600 ]; then
        echo "Lock obsoleto, removendo..."
        rm -rf "$LOCK_FILE"
        continue
      fi
    fi
    
    sleep 2
    elapsed=$((elapsed + 2))
  done
  
  return 1
}

release_lock() {
  if [ -d "$LOCK_FILE" ]; then
    rm -rf "$LOCK_FILE"
  fi
}

# Garantir liberaÃ§Ã£o do lock
trap release_lock EXIT

# Adquirir lock e executar migrations
if acquire_lock $LOCK_TIMEOUT; then
  echo "Applying migrations..."
  uv run python manage.py migrate --noinput || true
  release_lock
else
  echo "AVISO: Pulando migrations, outra instÃ¢ncia estÃ¡ executando"
fi
```

### BenefÃ­cios
- âœ… Lock atÃ´mico usando `mkdir` (operaÃ§Ã£o atÃ´mica POSIX)
- âœ… Timeout configurÃ¡vel (5 minutos)
- âœ… DetecÃ§Ã£o de lock obsoleto (>10 minutos)
- âœ… `trap` garante liberaÃ§Ã£o mesmo com erro
- âœ… MÃºltiplas replicas podem iniciar seguramente

---

## ğŸ“Š Resumo de Impacto

| Problema | Severidade | FrequÃªncia | Impacto | Status |
|----------|-----------|------------|---------|--------|
| Vazamento GPU | ğŸ”´ CrÃ­tica | Alta | OOM apÃ³s ~10 req | âœ… Resolvido |
| ValidaÃ§Ã£o arquivo | ğŸ”´ CrÃ­tica | MÃ©dia | OOM em arquivo grande | âœ… Resolvido |
| Deadlock async | ğŸ”´ CrÃ­tica | MÃ©dia | Workers mortos | âœ… Resolvido |
| Arquivos temp | ğŸŸ  Alta | Alta | Disco cheio em 24h | âœ… Resolvido |
| Redis desconexÃ£o | ğŸŸ  Alta | MÃ©dia | Fila quebrada | âœ… Resolvido |
| Cache corrompido | ğŸŸ  Alta | Baixa | Loop infinito | âœ… Resolvido |
| VÃ­deo corrompido | ğŸŸ  Alta | Baixa | Worker morto | âœ… Resolvido |
| Race condition | ğŸŸ¡ MÃ©dia | Baixa | Crash no startup | âœ… Resolvido |

---

## ğŸ§ª ValidaÃ§Ã£o

Execute o script de testes para validar as correÃ§Ãµes:

```bash
python test_crash_fixes.py
```

Testes implementados:
- âœ… Context manager de arquivos temporÃ¡rios
- âœ… ValidaÃ§Ã£o de cache corrompido
- âœ… Timeout de validaÃ§Ã£o de vÃ­deo
- âœ… Limpeza de memÃ³ria GPU
- âœ… ConfiguraÃ§Ã£o Celery resiliente
- âœ… Mecanismo de lock Docker

---

## ğŸš€ Deployment

Todas as correÃ§Ãµes sÃ£o **backward-compatible** e podem ser deployadas sem downtime:

1. **Pull da branch**: `git pull origin copilot/fix-crash-potential-issues`
2. **Rebuild containers**: `docker-compose build`
3. **Deploy gradual**: Rolling update recomendado
4. **Monitoramento**: Verificar logs por 24h

---

## ğŸ“ˆ MÃ©tricas de Sucesso

ApÃ³s deployment, monitorar:

1. **GPU Memory**: Deve estabilizar e nÃ£o crescer indefinidamente
2. **Disk Usage**: `/tmp/daredevil` nÃ£o deve crescer descontroladamente
3. **Task Queue**: Celery workers nÃ£o devem morrer
4. **Redis Connection**: Reconnect automÃ¡tico em falhas
5. **Cache Errors**: Logs de cache corrompido devem desaparecer
6. **Video Processing**: Timeouts apropriados para vÃ­deos grandes
7. **Migration Lock**: MÃºltiplas replicas iniciam sem erro

---

## ğŸ” Troubleshooting

Se encontrar problemas:

1. **OOM continua**: Verificar se `torch.cuda.empty_cache()` estÃ¡ sendo chamado
2. **Disco cheio**: Verificar logs de limpeza de arquivos temp
3. **Tasks travadas**: Verificar timeout e retry settings do Celery
4. **Redis desconectando**: Verificar `socket_keepalive` e health checks
5. **Cache invÃ¡lido**: Verificar logs de validaÃ§Ã£o de cache
6. **FFmpeg hang**: Verificar timeout adaptativo baseado em tamanho
7. **Migrations duplicadas**: Verificar lock file em `/tmp/`

---

## ğŸ“š ReferÃªncias

- [PyTorch CUDA Memory Management](https://pytorch.org/docs/stable/notes/cuda.html)
- [Celery Task Best Practices](https://docs.celeryproject.org/en/stable/userguide/tasks.html)
- [Redis Connection Pool](https://redis.io/topics/clients)
- [FFmpeg Timeout Handling](https://ffmpeg.org/ffmpeg.html)
- [Django File Upload Handling](https://docs.djangoproject.com/en/stable/topics/http/file-uploads/)

---

**Documento criado em**: 2025-11-06  
**VersÃ£o**: 1.0  
**Status**: Implementado e testado
