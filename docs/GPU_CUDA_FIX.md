# üöÄ Fix: PyTorch com CUDA para GPU Acceleration

## Problema Identificado

‚ùå **Whisper estava rodando em CPU** (n√£o em GPU), causando transcri√ß√£o lenta:
- 118 frames/s em CPU
- Esperado: 1000+ frames/s com GPU RTX 3060

**Verifica√ß√£o feita:**
```bash
docker compose exec celery_worker_gpu1 python3 -c "import torch; print(torch.cuda.is_available())"
# Resultado: ModuleNotFoundError: No module named 'torch'
```

**Diagn√≥stico:** PyTorch n√£o estava instalado no container!

---

## Solu√ß√£o Implementada

### 1. Adicionado PyTorch ao `pyproject.toml`

```toml
dependencies = [
    ...
    "torch>=2.0.0",  # ‚úÖ NOVO: PyTorch com CUDA 12.1
    ...
]
```

### 2. Atualizado `Dockerfile` para instalar PyTorch com CUDA 12.1

```dockerfile
# ‚úÖ NOVO: Instruir UV a usar PyTorch com CUDA 12.1
ENV UV_INDEX_STRATEGY=unsafe-best-match

# ‚úÖ NOVO: Instalar PyTorch com CUDA 12.1 explicitamente
RUN /root/.local/bin/uv pip install --system \
    --index-url https://download.pytorch.org/whl/cu121 \
    'torch>=2.0.0'
```

---

## Como Buildar

Execute este comando para rebuildar com PyTorch CUDA:

```bash
cd /home/marcus/projects/daredevil

# Build completo (reconstr√≥i todas as imagens)
docker compose up -d --build

# Ou apenas o worker GPU
docker compose build --no-cache celery_worker_gpu1
docker compose up -d celery_worker_gpu1
```

**Tempo esperado:** ~5-10 minutos (PyTorch + depend√™ncias = ~2GB)

---

## Verifica√ß√£o Ap√≥s Build

### 1. Verificar se PyTorch est√° instalado com CUDA:

```bash
docker compose exec celery_worker_gpu1 python3 -c \
  "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"
```

**Sa√≠da esperada:**
```
CUDA Available: True
Device: NVIDIA GeForce RTX 3060
```

### 2. Verificar se GPU est√° sendo usada:

```bash
docker compose exec celery_worker_gpu1 nvidia-smi
```

**Sa√≠da esperada (durante transcri√ß√£o):**
```
| NVIDIA GeForce RTX 3060    | 12288MiB | 2000MiB |    GPU Usage: 100%
```

### 3. Verificar logs de Whisper durante transcri√ß√£o:

```bash
docker compose logs celery_worker_gpu1 -f | grep -E "GPU|device|cuda"
```

**Sa√≠da esperada:**
```
GPU detectada: NVIDIA GeForce RTX 3060 (12.0GB VRAM)
Transcrevendo √°udio: ... (idioma: pt, device: cuda)
```

---

## Resultado Esperado Ap√≥s Fix

### Performance Comparison

| M√©trica | Antes (CPU) | Depois (GPU) | Melhoria |
|---------|------------|-------------|---------|
| Frames/s | 118 | 1000+ | 8-10x |
| Transcri√ß√£o de 1min | ~45s | ~5s | 9x mais r√°pido |
| Transcri√ß√£o de 10min | ~450s | ~50s | 9x mais r√°pido |
| Modelo (medium) | N/A | Usa FP16 | Reduz mem√≥ria |

### Exemplo de Log Esperado

**Antes (CPU - LENTO):**
```
31%|###       | 21260/69666 [02:56<06:50, 118.01frames/s]
(vai demorar ~9 minutos para 100%)
```

**Depois (GPU - R√ÅPIDO):**
```
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69666/69666 [00:35<00:00, 2000+frames/s]
(completa em ~35 segundos)
```

---

## Arquivos Modificados

1. ‚úÖ `pyproject.toml` - Adicionado `torch>=2.0.0`
2. ‚úÖ `Dockerfile` - Adicionadas linhas de instala√ß√£o de PyTorch com CUDA
3. ‚úÖ `uv.lock` - **Removido** (ser√° regenerado no build)

---

## Pr√≥ximos Passos

1. ‚è≥ Executar: `docker compose up -d --build`
2. ‚è≥ Esperar build completar (~5-10 minutos)
3. ‚è≥ Testar com: `docker compose exec celery_worker_gpu1 nvidia-smi`
4. ‚è≥ Submeter um √°udio para transcri√ß√£o e verificar se est√° r√°pido
5. ‚è≥ Ver logs: `docker compose logs celery_worker_gpu1 -f`

---

## Troubleshooting

### Se ainda estiver lento (CPU):

```bash
# 1. Verificar se CUDA est√° realmente dispon√≠vel
docker compose exec celery_worker_gpu1 python3 -c "import torch; print(torch.cuda.is_available())"

# 2. Se retornar False, verificar logs do build
docker compose logs web | grep -i "torch\|cuda\|install"

# 3. Se necess√°rio, for√ßar rebuild limpo
docker compose down
docker system prune -a
docker compose up -d --build
```

### Se PyTorch n√£o instalar:

O problema pode ser:
1. ‚ùå Imagem base `nvidia/cuda:12.1.0` n√£o tem CUDA runtime
   - **Solu√ß√£o:** Trocar para `nvidia/cuda:12.1.0-runtime-ubuntu22.04`
2. ‚ùå √çndice PyTorch indispon√≠vel
   - **Solu√ß√£o:** Usar `--index-url https://download.pytorch.org/whl/cu121`
3. ‚ùå Mem√≥ria insuficiente durante build
   - **Solu√ß√£o:** Aumentar Docker memory allocation

---

## Refer√™ncia

- **PyTorch CUDA Wheels:** https://download.pytorch.org/whl/cu121
- **NVIDIA CUDA 12.1:** https://developer.nvidia.com/cuda-12-1-0-download-archive
- **Whisper Performance:** Com GPU RTX 3060, espera-se 8-10x speedup

---

**Status:** ‚úÖ Implementado
**Pr√≥ximo:** Executar build e testar performance
