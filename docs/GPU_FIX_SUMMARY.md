# üìä Resumo de Mudan√ßas - Performance GPU

## üéØ O que foi descoberto

Transcri√ß√£o estava **lenta** (118 frames/s) porque:
- ‚ùå PyTorch **n√£o estava instalado** no container
- ‚ùå Whisper rodava em **CPU em vez de GPU**
- ‚ùå RTX 3060 dispon√≠vel mas **n√£o sendo usada**

---

## ‚úÖ O que foi corrigido

### 1Ô∏è‚É£ `pyproject.toml`
```diff
dependencies = [
    ...
+   "torch>=2.0.0",  # ‚úÖ PyTorch com CUDA 12.1
    "pydub>=0.25.1",
    ...
]
```

### 2Ô∏è‚É£ `Dockerfile`
```diff
# Adicionar UV ao PATH permanentemente
ENV PATH="/root/.local/bin:$PATH"

+# ‚úÖ Instruir UV a usar PyTorch com CUDA 12.1
+ENV UV_INDEX_STRATEGY=unsafe-best-match

# Copiar arquivos do projeto
COPY pyproject.toml uv.lock* /app/
COPY . /app/

+# ‚úÖ Instalar PyTorch com CUDA 12.1 explicitamente
+RUN /root/.local/bin/uv pip install --system \
+    --index-url https://download.pytorch.org/whl/cu121 \
+    'torch>=2.0.0'

# Tornar os scripts execut√°veis
RUN chmod +x /app/docker-entrypoint.sh /app/scripts/gpu_worker.sh
```

### 3Ô∏è‚É£ `uv.lock`
```diff
- uv.lock (arquivo removido, ser√° regenerado)
```

---

## üöÄ Como Executar

```bash
cd /home/marcus/projects/daredevil
docker compose up -d --build
```

**Tempo:** ~5-10 minutos (download + compila√ß√£o de PyTorch)

---

## ‚úîÔ∏è Como Verificar

Ap√≥s o build completar:

```bash
# Verificar se CUDA est√° dispon√≠vel
docker compose exec celery_worker_gpu1 python3 -c \
  "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"

# Esperado: CUDA: True, GPU: NVIDIA GeForce RTX 3060
```

---

## üìà Performance Esperada

| Item | Antes | Depois | Ganho |
|------|-------|--------|-------|
| Frames/s | 118 | 1000+ | **8-10x** |
| 1 minuto √°udio | 45s | 5s | **9x** |
| 10 minutos √°udio | 450s (7:30) | 50s | **9x** |

---

## üìö Documenta√ß√£o

Ver arquivo completo em: `docs/GPU_CUDA_FIX.md`

---

**Status:** ‚úÖ Pronto para build
**Pr√≥ximo:** `docker compose up -d --build`
