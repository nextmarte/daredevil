# Daredevil - API de TranscriÃ§Ã£o de Ãudio ğŸ™ï¸

API de transcriÃ§Ã£o de Ã¡udio em portuguÃªs usando Django Ninja e Whisper (OpenAI). Suporta mÃºltiplos formatos de Ã¡udio, incluindo formatos do WhatsApp e Instagram.

## ğŸš€ CaracterÃ­sticas

- âœ… TranscriÃ§Ã£o de alta qualidade usando Whisper
- âœ… Otimizado para portuguÃªs brasileiro
- âœ… **AceleraÃ§Ã£o por GPU (NVIDIA CUDA)** para processamento atÃ© 10x mais rÃ¡pido
- âœ… Suporte a mÃºltiplos formatos: WhatsApp (.opus, .ogg), Instagram (.mp4, .m4a), e formatos padrÃ£o (.mp3, .wav, .flac)
- âœ… TranscriÃ§Ã£o com timestamps detalhados
- âœ… Processamento em lote
- âœ… API RESTful moderna com Django Ninja
- âœ… DocumentaÃ§Ã£o automÃ¡tica (Swagger/OpenAPI)
- âœ… ValidaÃ§Ã£o automÃ¡tica com Pydantic
- âœ… Deploy com Docker e suporte a GPU

## ğŸ“‹ Requisitos

- Python 3.12+
- uv (gerenciador de pacotes)
- ffmpeg (para processamento de Ã¡udio)
- **GPU NVIDIA (opcional)**: Para aceleraÃ§Ã£o de processamento com CUDA

### Instalar ffmpeg

```bash
# Ubuntu/Debian
sudo apt-get update && sudo apt-get install -y ffmpeg

# macOS
brew install ffmpeg

# Arch Linux
sudo pacman -S ffmpeg
```

### GPU Support (Opcional)

Para habilitar aceleraÃ§Ã£o por GPU NVIDIA, consulte o guia completo: **[GPU_SETUP.md](GPU_SETUP.md)**

**BenefÃ­cios da GPU:**
- Processamento 5-10x mais rÃ¡pido
- Suporte a modelos maiores (large) sem lentidÃ£o
- Melhor para processamento em lote

## ğŸ› ï¸ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/seu-usuario/daredevil.git
cd daredevil
```

2. **Instale as dependÃªncias com uv:**
```bash
uv sync
```

3. **Configure as variÃ¡veis de ambiente:**
```bash
cp .env.example .env
# Edite o .env conforme necessÃ¡rio
```

4. **Execute as migraÃ§Ãµes:**
```bash
uv run python manage.py migrate
```

5. **Inicie o servidor:**
```bash
uv run python manage.py runserver
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:8000/api/`

## ğŸ“š DocumentaÃ§Ã£o da API

ApÃ³s iniciar o servidor, acesse:

- **Swagger UI**: `http://localhost:8000/api/docs`
- **ReDoc**: `http://localhost:8000/api/redoc`
- **OpenAPI Schema**: `http://localhost:8000/api/openapi.json`

## ğŸ¯ Endpoints

### Health Check
```bash
GET /api/health
```

Verifica o status da API e configuraÃ§Ãµes.

### GPU Status
```bash
GET /api/gpu-status
```

Verifica se GPU estÃ¡ disponÃ­vel e mostra informaÃ§Ãµes de memÃ³ria.

**Exemplo de resposta com GPU:**
```json
{
  "gpu_available": true,
  "device": "cuda",
  "gpu_count": 1,
  "gpus": [
    {
      "id": 0,
      "name": "NVIDIA GeForce RTX 3060",
      "memory_allocated_gb": 2.5,
      "memory_reserved_gb": 3.0,
      "memory_total_gb": 12.0,
      "memory_free_gb": 9.0,
      "compute_capability": "8.6"
    }
  ]
}
```

### Transcrever Ãudio
```bash
POST /api/transcribe
```

**ParÃ¢metros:**
- `file`: Arquivo de Ã¡udio (multipart/form-data)
- `language`: CÃ³digo do idioma (padrÃ£o: "pt")
- `model`: Modelo Whisper (opcional: tiny, base, small, medium, large)

**Exemplo com curl:**
```bash
curl -X POST "http://localhost:8000/api/transcribe" \
  -F "file=@audio.mp3" \
  -F "language=pt"
```

**Resposta:**
```json
{
  "success": true,
  "transcription": {
    "text": "OlÃ¡, como vocÃª estÃ¡?",
    "segments": [
      {
        "start": 0.0,
        "end": 2.5,
        "text": "OlÃ¡, como vocÃª estÃ¡?",
        "confidence": 0.95
      }
    ],
    "language": "pt",
    "duration": 2.5
  },
  "processing_time": 3.2,
  "audio_info": {
    "format": "mp3",
    "duration": 2.5,
    "sample_rate": 44100,
    "channels": 2,
    "file_size_mb": 0.5
  }
}
```

### Transcrever em Lote
```bash
POST /api/transcribe/batch
```

**ParÃ¢metros:**
- `files`: Lista de arquivos de Ã¡udio
- `language`: CÃ³digo do idioma (padrÃ£o: "pt")
- `model`: Modelo Whisper (opcional)

### Formatos Suportados
```bash
GET /api/formats
```

Lista todos os formatos de Ã¡udio suportados.

## ğŸ“ Formatos Suportados

### WhatsApp
- `.opus`
- `.ogg`
- `.m4a`
- `.aac`

### Instagram
- `.mp4` (extraÃ§Ã£o de Ã¡udio)
- `.m4a`
- `.aac`

### Formatos PadrÃ£o
- `.mp3`
- `.wav`
- `.flac`
- `.webm`

**Limite de tamanho:** 25MB por arquivo (configurÃ¡vel)

## âš™ï¸ ConfiguraÃ§Ã£o

Edite o arquivo `.env` para personalizar:

```env
# Modelo Whisper (tiny, base, small, medium, large)
WHISPER_MODEL=medium

# Tamanho mÃ¡ximo de arquivo em MB
MAX_AUDIO_SIZE_MB=25

# DiretÃ³rio temporÃ¡rio
TEMP_AUDIO_DIR=/tmp/daredevil

# Habilitar cache
ENABLE_CACHE=true

# NÃ­vel de log
LOG_LEVEL=INFO
```

### Modelos Whisper

| Modelo | Tamanho | RAM NecessÃ¡ria | GPU VRAM | Velocidade (CPU) | Velocidade (GPU) | Qualidade |
|--------|---------|----------------|----------|------------------|------------------|-----------|
| tiny   | ~39 MB  | ~1 GB          | ~1 GB    | Muito rÃ¡pido     | Extremamente rÃ¡pido | BÃ¡sica |
| base   | ~74 MB  | ~1 GB          | ~1 GB    | RÃ¡pido           | Muito rÃ¡pido     | Boa    |
| small  | ~244 MB | ~2 GB          | ~2 GB    | Moderado         | RÃ¡pido           | Muito boa |
| medium | ~769 MB | ~5 GB          | ~5 GB    | Lento            | Moderado         | Excelente |
| large  | ~1.5 GB | ~10 GB         | ~10 GB   | Muito lento      | Moderado         | Melhor |

**RecomendaÃ§Ã£o:** 
- Com CPU: Use `small` ou `medium`
- Com GPU: Use `medium` ou `large` para melhor qualidade

## ğŸ§ª Testando

### Testar configuraÃ§Ã£o da GPU
```bash
uv run python test_gpu.py
```

Este script verifica:
- Se NVIDIA drivers estÃ£o instalados
- Se PyTorch detecta a GPU
- Se Whisper pode usar a GPU
- InformaÃ§Ãµes de memÃ³ria e capacidade da GPU

### Teste rÃ¡pido com Python
```python
import requests

url = "http://localhost:8000/api/transcribe"
files = {"file": open("audio.mp3", "rb")}
data = {"language": "pt"}

response = requests.post(url, files=files, data=data)
print(response.json())
```

### Teste com Ã¡udio do WhatsApp
```bash
curl -X POST "http://localhost:8000/api/transcribe" \
  -F "file=@whatsapp_audio.opus" \
  -F "language=pt"
```

## ğŸ—ï¸ Estrutura do Projeto

```
daredevil/
â”œâ”€â”€ config/              # ConfiguraÃ§Ãµes Django
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ transcription/       # App de transcriÃ§Ã£o
â”‚   â”œâ”€â”€ api.py          # Endpoints da API
â”‚   â”œâ”€â”€ schemas.py      # Modelos Pydantic
â”‚   â””â”€â”€ services.py     # LÃ³gica de negÃ³cio
â”œâ”€â”€ .env.example        # Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md  # InstruÃ§Ãµes para GitHub Copilot
â”œâ”€â”€ manage.py
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸ”§ Desenvolvimento

### Adicionar nova dependÃªncia
```bash
uv add nome-do-pacote
```

### Executar comandos Django
```bash
uv run python manage.py <comando>
```

### Ativar ambiente virtual (opcional)
```bash
source .venv/bin/activate
```

## ğŸ“ LicenÃ§a

MIT

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests.

## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no GitHub.

---

**Nota:** O modelo Whisper serÃ¡ baixado automaticamente na primeira execuÃ§Ã£o (~1-3GB dependendo do modelo escolhido).
